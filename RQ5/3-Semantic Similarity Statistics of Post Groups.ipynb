{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis.gensim_models\n",
    "import jieba.posseg as jp,jieba\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "def extract_info(x):\n",
    "    CreationDate = re.findall(r'CreationDate = (.*?)//',x)[0]\n",
    "\n",
    "    Title = re.findall(r'Title = (.*?)//',x)[0]\n",
    "\n",
    "    Tags = re.findall(r'Tags = (.*?)//',x)[0]\n",
    "    Tags = Tags.split('><')\n",
    "    Tags[0] = Tags[0].lstrip('<')\n",
    "    Tags[-1] = Tags[-1].rstrip('>')\n",
    "    Tags = ' '.join(Tags)\n",
    "\n",
    "    Score = re.findall(r'Score = (.*?)//',x)[0]\n",
    "\n",
    "\n",
    "    AnswerCount = re.findall(r'AnswerCount = (.*?)//',x)\n",
    "    if AnswerCount==[] or AnswerCount==['']:\n",
    "        AnswerCount = re.findall(r'AnswerCount = (.*?)\\n',x)\n",
    "        if AnswerCount == [] or AnswerCount==['']:\n",
    "            AnswerCount = None\n",
    "        else:\n",
    "            AnswerCount = AnswerCount[0]\n",
    "    else:\n",
    "        AnswerCount = AnswerCount[0]\n",
    "\n",
    "\n",
    "    CommentCount = re.findall(r'CommentCount = (.*?)//',x)\n",
    "    if CommentCount==[] or CommentCount==['']:\n",
    "        CommentCount = re.findall(r'CommentCount = (.*?)\\n',x)\n",
    "        if CommentCount==[] or CommentCount==['']:\n",
    "            CommentCount = None\n",
    "        else:\n",
    "            CommentCount = CommentCount[0]\n",
    "    else:\n",
    "        CommentCount = CommentCount[0]\n",
    "\n",
    "    FavoriteCount = re.findall(r'FavoriteCount = (.*?)//',x)\n",
    "    if FavoriteCount==[] or FavoriteCount==['']:\n",
    "        FavoriteCount = re.findall(r'FavoriteCount = (.*?)\\n',x)\n",
    "        if FavoriteCount==[] or FavoriteCount==['']:\n",
    "            FavoriteCount = None\n",
    "        else:\n",
    "            FavoriteCount = FavoriteCount[0]\n",
    "    else:\n",
    "        FavoriteCount = FavoriteCount[0]\n",
    "\n",
    "\n",
    "\n",
    "    return CreationDate, Title, Tags, Score, AnswerCount, CommentCount, FavoriteCount"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "path1 = 'D:/CCFinder/Commit2So(A commit will correspond to multiple sos)/'\n",
    "list1 = os.listdir(path1)\n",
    "len(list1),list1[0]\n",
    "\n",
    "\n",
    "with open('./commit_name.txt','w', encoding='utf-8') as f:\n",
    "    for i in list1:\n",
    "        f.write(i)\n",
    "        f.write('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "w2v_model = word2vec.Word2Vec.load('./word2vec.model')\n",
    "\n",
    "def mean_vector(words):\n",
    "    vec = np.zeros(300).reshape((1, 300))\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec += w2v_model[word].reshape((1, 300))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return_vec = vec/len(words)\n",
    "    return_vec = return_vec.reshape((300,))\n",
    "    return return_vec.tolist()\n",
    "\n",
    "\n",
    "# def max_vector(words):\n",
    "#     vec = np.zeros(300).reshape((1, 300))\n",
    "#     for word in words:\n",
    "#         try:\n",
    "#             vec = np.concatenate((vec, w2v_model[word].reshape((1, 300))),axis=0)\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#     return_vec = vec.max(axis=0)\n",
    "#     return return_vec.tolist()\n",
    "\n",
    "def separate_sentence(text):\n",
    "    remove_chars = '[·’!\"\\#$%&\\'()＃！（）*+,-./:;<=>?\\@，：?￥★、…．＞【】［］《》？“”‘’\\[\\\\]^_`{|}~]+'\n",
    "    text = re.sub(remove_chars, \"\", text)\n",
    "\n",
    "    disease_List = nltk.word_tokenize(text)\n",
    "\n",
    "    filtered = [w for w in disease_List if(w not in stopwords.words('english'))]\n",
    "\n",
    "    Rfiltered =nltk.pos_tag(filtered)\n",
    "\n",
    "    filter_word = [i[0] for i in Rfiltered]\n",
    "    return filter_word\n",
    "\n",
    "\n",
    "def return_w2v(text):\n",
    "    words_list = separate_sentence(text)\n",
    "    vec = mean_vector(words_list)\n",
    "\n",
    "    return vec\n",
    "\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a_norm = np.linalg.norm(a)\n",
    "    b_norm = np.linalg.norm(b)\n",
    "    cos = np.dot(a,b)/(a_norm * b_norm)\n",
    "    return cos\n",
    "\n",
    "\n",
    "def return_center(w2v_df):\n",
    "    nums = len(w2v_df)\n",
    "    res = np.zeros((300,))\n",
    "\n",
    "    for i in range(nums):\n",
    "        res += np.array(w2v_df[i])\n",
    "\n",
    "    return res/nums\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21622/21622 [1:53:03<00:00,  3.19it/s]   \n"
     ]
    }
   ],
   "source": [
    "# all_similarity = []\n",
    "all_sse = []\n",
    "for file in tqdm(list1):\n",
    "    CreationDate_list = []\n",
    "    Title_list = []\n",
    "    Tags_list = []\n",
    "    Score_list = []\n",
    "    AnswerCount_list = []\n",
    "    CommentCount_list = []\n",
    "    FavoriteCount_list = []\n",
    "    with open(path1+file, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        #lines = list(set(lines))\n",
    "        if len(lines) < 2:\n",
    "            all_sse.append(np.nan)\n",
    "            continue\n",
    "        for l in lines:\n",
    "            CreationDate, Title, Tags, Score, AnswerCount, CommentCount, FavoriteCount = extract_info(l)\n",
    "            CreationDate_list.append(CreationDate)\n",
    "            Title_list.append(Title)\n",
    "            Tags_list.append(Tags)\n",
    "            Score_list.append(Score)\n",
    "            AnswerCount_list.append(AnswerCount)\n",
    "            CommentCount_list.append(CommentCount)\n",
    "            FavoriteCount_list.append(FavoriteCount)\n",
    "\n",
    "    new_df = pd.DataFrame({'CreationDate':[],'Title':[], 'Tags':[],\n",
    "                          'Score':[],'AnswerCount':[], 'CommentCount':[],\n",
    "                          'FavoriteCount':[]})\n",
    "    new_df['CreationDate'] = CreationDate_list\n",
    "    new_df['Title'] = Title_list\n",
    "    new_df['Tags'] = Tags_list\n",
    "    new_df['Score'] = Score_list\n",
    "    new_df['AnswerCount'] = AnswerCount_list\n",
    "    new_df['CommentCount'] = CommentCount_list\n",
    "    new_df['FavoriteCount'] =FavoriteCount_list\n",
    "    # print(new_df.info())\n",
    "\n",
    "\n",
    "\n",
    "    text = new_df['Title'] + pd.Series([' ']*len(new_df)) + new_df['Tags']\n",
    "    # text = text.to_list()\n",
    "    w2v_df = text.apply(lambda x: return_w2v(x))\n",
    "    center_vec = return_center(w2v_df)\n",
    "    nums_vec = len(w2v_df)\n",
    "    sum_vec = 0\n",
    "    for i in range(nums_vec):\n",
    "        sum_vec += ((np.array(w2v_df[i])-center_vec)**2).sum()\n",
    "    # similarity_list = []\n",
    "    # for i in range(len(w2v_df)):\n",
    "    #     for j in range(i+1,len(w2v_df)):\n",
    "    #         similarity_list.append(cos_sim(w2v_df[i],w2v_df[j]))\n",
    "    #\n",
    "    # all_similarity.append(np.mean(similarity_list))\n",
    "    all_sse.append(sum_vec/nums_vec)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "all_sse = pd.Series(all_sse)\n",
    "all_sse.to_csv('./all_sse.txt', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "21622"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}